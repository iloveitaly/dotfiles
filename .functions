tmux-kill-detached-sessions() {
  sleep 10

  # TODO add `all` param and remove the digit grep to kill all unattached sessions
  # `grep -v attached | grep -E '^\d{1,3}'` will only grab non-vs-code sessions

  tmux list-sessions | grep -v attached | awk -F: '{print $1}' | xargs -I {} tmux kill-session -t {}
}

zinit-update() {
  zinit delete --clean
  zinit update --all
  zinit cclear
}

# pass path to image to copy it to clipboard
pbcopy-image() {
  if [ -z "$1" ]; then
    set -- "$(pbpaste)"
  fi

  if [ ! -f "$1" ]; then
    echo "Error: File $1 does not exist."
    return 1
  fi

  osascript -e "set the clipboard to (read (POSIX file \"$1\") as JPEG picture)"
}

# use plugin name as initial parameter
asdf-current-version() {
  # if the version DNE then asdf will print an error to stderr
  asdf current $@ 2>&1 | awk '{print $2}'
}

# Loop through all arguments (assumed to be asdf plugins)
asdf-generate-tool-versions() {
  for plugin in "$@"; do
    version=$(asdf-current-version "$plugin")

    if [ "$version" != "Not" ]; then
      echo "$plugin $version" >> .tool-versions
    else
      echo "Error: Version for $plugin not found."
    fi
  done
}

# use plugin name as initial parameter
asdf-reinstall() {
  asdf uninstall $@ $(asdf-current-version $@)
}

###########################
# Python Utilities
###########################

# create a file to automatically run code on startup
python-inject-startup() {
  local target_file=$(python -c "import site; print(site.getsitepackages()[0])")/mbianco-injection.py

  if [[ -f "$target_file" ]]; then
    echo "python startup already exists: $target_file"
    return 1
  fi

  cat << 'EOF' > "$target_file"
def run_startup_script():
  try:
    import pretty_traceback
    pretty_traceback.install()
  except ImportError:
    pass

run_startup_script()
EOF

  echo "Python startup injection created: $target_file"
}

pyd() {
    local executable=$1

  if ! [ -f "$executable" ]; then
    executable=$(which "$executable")
  fi

  echo "$executable ${@:2}"
  eval "ipdb3 -c continue -- $executable ${@:2}"
}

# when hacking on a package with `pip-show` this will properly wipe + reinstall the package
# also allows installing a package from a git repo
pip-pristine() {
  if [[ $1 == http* ]]; then
    # Fetch pyproject.toml from GitHub using Python's requests library
    package_name=$(python -c "
import requests
import toml
from io import StringIO

try:
    response = requests.get('$1/raw/main/pyproject.toml')
    response.raise_for_status()
except requests.exceptions.HTTPError:
    # If fetching from the 'main' branch fails, try the 'master' branch
    response = requests.get('$1/raw/master/pyproject.toml')

data = StringIO(response.text)
config = toml.load(data)
print(config['tool']['poetry']['name'])
")
    pip uninstall -y $package_name
    pip cache remove $package_name
  else
    pip uninstall -y $1
    pip cache remove $1
  fi

  pip install $1
}

# find the location of a pip package
pip-show() {
  # convert - => _
  package_name=${1//-/_}

  package_path=$(pip show $package_name | grep "Location:" | awk '{print $2}' | tr -d "\n")/$package_name

  echo $package_path
  cd $package_path
  code $package_path
}

###########################
# Network Sniffing
###########################

start_network_proxy() {
    SERVICE="Ethernet"
    PROXY_ADDRESS="localhost"
    PROXY_PORT="8084"

    disable_proxy() {
        echo "Disabling proxies for $SERVICE..."
        sudo networksetup -setsocksfirewallproxystate "$SERVICE" off
        echo "Proxies disabled for $SERVICE"
    }

    # Check if the mitmproxy certificate is in the keychain
    if [[ -z $(security find-certificate -a -c "mitmproxy" -p) ]]; then
        echo "mitmproxy certificate not found in the system keychain. Adding it now..."
        sudo security add-trusted-cert -d -p ssl -p basic -k /Library/Keychains/System.keychain ~/.mitmproxy/mitmproxy-ca-cert.pem
    else
        echo "mitmproxy certificate is already in the system keychain."
    fi

    echo "Starting mitmproxy on port $PROXY_PORT..."

    # Set SOCKS5 proxy
    sudo networksetup -setsocksfirewallproxy "$SERVICE" "$PROXY_ADDRESS" "$PROXY_PORT"
    sudo networksetup -setsocksfirewallproxystate "$SERVICE" on

    echo "SOCKS5 proxy set for $SERVICE"

    # Start mitmproxy in SOCKS5 mode with TLS version adjustment
    mitmproxy --mode socks5 --listen-port $PROXY_PORT --set tls_version_client_min=SSL3

    # Clean up proxy settings after mitmproxy exits
    disable_proxy
}

###########################
# Docker Utilities
###########################

# Usage: docker-shell container_name user
#   - container name (can be partial) as first arg
#   - [optional] user as second arg
#
# Description: shell inside of existing container
docker-shell() {
  local container_ids=($(docker ps -aqf "name=$1"))
  local user_option=""

  if [ ${#container_ids[@]} -gt 1 ]; then
    echo "Error: Multiple containers match the name '$1'."
    return 1
  elif [ ${#container_ids[@]} -eq 0 ]; then
    echo "Error: No containers found matching the name '$1'."
    return 1
  fi

  local container_id=${container_ids[0]}

  if [ -n "${2-}" ]; then
    user_option="-u $2"
  fi

  eval "docker exec -it $user_option $container_id bash"
}


# get files that would be included in a Dockerfile, with size in megabytes
dockerignore-test() {
  rsync --dry-run -av --exclude-from='.dockerignore' --out-format="%l %n" ./ /tmp/ | \
    awk '{size_mb = $1 / (1024 * 1024); printf "%.2f MB %s\n", size_mb, $2}' | \
    sort -k1,1nr -k2,2 | \
    less
}

# TODO docker-new-bash, run instead of exec

# add key to remove server
# ssh-add-key <server>
ssh-add-key() {
  ssh-copy-id -i ~/.ssh/id_rsa.pub $1
  ssh $1
}

# useful for cleaning up text from tmux
# trims whitespace and removes quotes (single and double) if they are trailing + leading
trim-and-unquote() {
  sed -E 's/^[ \t]+//;s/[ \t]+$//;s/^['\''"](.*)['\''"]$/\1/'
}

# a touch command which creates folders too
function touchp() {
  mkdir -p $(dirname $1) && touch "$1"
}

# All the dig info
function digga() {
  dig +nocmd "$1" any +multiline +noall +answer
}

# add a license to an existing project/repo
add_mit_license() {
  # Check if the current folder is tied to a GitHub repository
  if ! gh repo view > /dev/null 2>&1; then
    echo "This folder is not tied to a GitHub repository. Aborting."
    return 1
  fi

  # Check if any LICENSE file exists
  if [[ -e LICENSE || -e LICENSE.md || -e LICENSE.txt ]]; then
    echo "A LICENSE file already exists. Aborting."
    return 1
  fi

  local license_template
  local repo_info
  local repo_name
  local author
  local year

  # Fetch the MIT license template
  license_template=$(gh api /licenses/MIT --jq '.body')

  # Get repository details
  repo_info=$(gh repo view --json nameWithOwner --jq '.nameWithOwner')
  repo_name=$(basename "$repo_info")
  author=$(git config user.name)
  year=$(date +%Y)

  # Replace placeholders in the license template
  local license_content
  license_content=${license_template//\[year\]/$year}
  license_content=${license_content//\[fullname\]/$author}

  # Write the license to LICENSE.md
  echo "$license_content" > LICENSE.md

  echo "MIT License added to the repository."
}

# if a PR is closed when it shouldn't have been, reopen it with one click!
github_reopen_pr() {
  local PR_URL="$1"
  local REPO PR_NUMBER PR_DETAILS TITLE BODY HEAD_REF

  REPO=$(echo $PR_URL | awk -F '/pull/' '{print $1}' | sed 's|https://github.com/||')
  PR_NUMBER=$(echo $PR_URL | awk -F '/pull/' '{print $2}')
  PR_DETAILS=$(gh pr view $PR_NUMBER --repo $REPO --json title,body,headRefName,headRepositoryOwner)
  BASE_BRANCH=$(gh repo view $REPO --json defaultBranchRef --jq '.defaultBranchRef.name')

  TITLE=$(jq -r .title <<< "$PR_DETAILS")
  BODY=$(jq -r .body <<< "$PR_DETAILS")
  HEAD_REF=$(jq -r .headRefName <<< "$PR_DETAILS")
  HEAD_REPO_OWNER=$(jq -r .headRepositoryOwner.login <<< "$PR_DETAILS")


  gh pr create --repo "$REPO" --title "$TITLE" --body "$BODY" --head "$HEAD_REPO_OWNER:$HEAD_REF" --base "$BASE_BRANCH"
}

# for quick gpt prompt generation
files-to-markdown() {
  for file in "$@"; do
    if [[ -f "$file" ]]; then
      echo "### File: $file"
      echo '```'
      cat "$file"
      echo '```'
      echo ''
    else
      echo "File $file does not exist." >&2
    fi
  done
}

# TODO add to remote-logout repo
# https://github.com/iloveitaly/remote-logout
# https://serverfault.com/questions/10404/log-out-graphical-user-from-command-line
macos-logout() {
  if [ -z "$1" ]; then
    echo "Error: No user specified."
    return 1
  fi

  if ! id -u "$1" > /dev/null 2>&1; then
    echo "Error: User $1 does not exist."
    return 1
  fi

  sudo launchctl bootout user/$(id -u "$1")
  sudo pkill -u "$1"

  # may need to kill WindowManager here too, looks like that is the one that gets tripped up
}

copy_with_context() {
  local file=$1
  local line=$2

  if [[ -z "$file" ]]; then
    echo "Usage: copy_with_context <file> <line> | <file-with-line>"
    return 1
  fi

  # if line DNE, then it must be embedded in the first argument
  if [[ -z "$line" ]]; then
    IFS=':' read file line _other <<< "$file"
  fi

  # check if $line is a number
  if ! [[ $line =~ ^[0-9]+$ ]]; then
    echo "Error: Line number must be a number (extracted line: $line)."
    return 1
  fi

  local context=10

  local start=$((line - context > 0 ? line - context : 1))
  local end=$((line + context))

  sed -n "${start},${end}p" "$file" | pbcopy
}

##################################
# Local Written-by-me Code Search
##################################

index_local_repositories() {
  fd --hidden --type=directory "\.git$" ~/Projects -x sh -c '
    repo=$(dirname "$0")
    origin=$(git -C "$repo" remote get-url origin 2>/dev/null)
    if [[ -z "$origin" ]] || [[ "$origin" == *"github.com/iloveitaly/"* ]]; then
      if [[ -z "$origin" ]] || ! git -C "$repo" remote get-url upstream &>/dev/null; then
        echo "$repo"
      fi
    fi
  ' {} \; > ~/.local-git-repos
}

# ripgrep code search
rgc() {
  if [[ ! -f ~/.local-git-repos ]]; then
    index_local_repositories
  fi

  if [[ $(find ~/.local-git-repos -mtime +7) ]]; then
    # reindex async if it hasn't been done in awhile
    index_local_repositories &
  fi

  # an alternative to `cut` is using -r rg option to mutate the content output
  # https://github.com/BurntSushi/ripgrep/issues/2860
  rg "$@" $(cat ~/.local-git-repos) | \
    # we don't want column, just file and line
    cut -d: -f1-2 | \
    # now that we only have file + line, we can remove duplicates
    uniq | \
    # nth will still display `:`, which is annoying
    fzf --ansi --delimiter : --with-nth '1' \
      --keep-right \
      --preview 'height=$(tput lines); start={2}; context=$((height / 2)); bat --color=always --paging=never --highlight-line {2} --line-range $((start > context ? start - context : 1)):$((start + context)) {1}'
}

###########################
# Local Filesystem Searches
###########################

# determine if we are in a node_modules folder or if a valid node_modules path was passed via any argument
function _is_node_modules() {
  local node_modules_path=$1

  if [[ -z "$node_modules_path" ]]; then
    node_modules_path=$(pwd)
  fi

  [[ "$node_modules_path" =~ node_modules$ ]]
}

function _is_venv() {
  local venv_path=$1

  if [[ -z "$venv_path" ]]; then
    venv_path=$(pwd)
  fi

  [[ "$venv_path" =~ \.venv$ ]]
}

alias ff="fzf --preview='bat --color=always {}'"

# TODO this should use the `cd` thing and just overload there instead
# fd + fzf, cd into the selected directory
fdd() {
  local additional_args=""

  if _is_node_modules "$@" || _is_venv "$@"; then
    additional_args="--no-ignore-vcs --hidden"
  fi

  local file_or_directory=$(fd ${=additional_args} "$@" | fzf --preview 'if [ -d {} ]; then exa -1 --color=always {}; elif [ -f {} ]; then cat {}; fi')

  # cd into dir or view the file
  if [[ -n "$file_or_directory" ]]; then
    if [[ -d "$file_or_directory" ]]; then
      cd "$file_or_directory"
    elif [[ -f "$file_or_directory" ]]; then
      cat "$file_or_directory"
    fi
  fi
}

RIPGREP_LIVEGREP_EXCLUSIONS=("--glob=!.git/**" "--glob=!.venv" "--glob=!.pnpm" "--glob=!node_modules" "--glob=!.tox" "--glob=!cdk.out")

# TODO add fzf support
# search all files in the current directory
rgu() {
  # TODO use glob list from find-replace
  rg -uu "${RIPGREP_LIVEGREP_EXCLUSIONS[@]}" "$@"
}

# livegrep-like local search
# related: https://github.com/seletskiy/zsh-fuzzy-search-and-edit/blob/master/plugin.zsh
rgg() {
  local additional_args=""

  # TODO should check search page in $@ as well
  if [[ $(pwd) =~ node_modules$ ]] || [[ $(pwd) == *"/.venv/"* ]]; then
    # in this case, we want to search the contents of the node_modules directory
    # this is a common case for me, trying to debug various package bugs in a project I'm working on
    additional_args="--no-ignore-vcs --hidden"
  fi

  # TODO --bind=\"ctrl-y:execute-silent(echo {} | cut -d: -f1 | tr -d '[:space:]' | pbcopy)\" \
  local file_and_location=$(rg --color always --hidden "$@" ${=additional_args} | fzf --ansi --delimiter : --with-nth '1,4' --preview 'height=$(tput lines); start={2}; context=$((height / 2)); bat --color=always --paging=never --highlight-line {2} --line-range $((start > context ? start - context : 1)):$((start + context)) {1}')

  # Extracting the file name from the selected line
  local file=$(echo "$file_and_location" | awk -F: '{print $1}')

  if [[ ! -z "$file" ]]; then
    open "$file"
  fi
}

# combine all matching files into a single string and copy to clipboard, helpful for AI stuff
find_and_bundle() {
  # $1 is the first argument to the function: the specific string to search for

  # Ensure the search string is provided
  if [[ -z "$1" ]]; then
    echo "Usage: find_and_bundle <string>"
    return 1
  fi

  # Use ripgrep to find files containing the specific string
  local files_with_string=($(rg --files-with-matches --no-messages --fixed-strings "$1"))

  # Check if any files were found
  if [[ ${#files_with_string[@]} -eq 0 ]]; then
    echo "No files found with string: $1"
    return 1
  fi

  # Combine contents of the files, separated by "---"
  for file in $files_with_string; do
    cat "$file"
    echo "\n---\n"
  done | pbcopy  # Copy the combined content to the clipboard
}


# gits: git history search
function gits() {
  # Check if a search string was passed
  if [[ -z "$1" ]]; then
    echo "Usage: gits <string-to-search-in-git-history>"
    return 1
  fi

  local search_string=$1

  git log --all --pickaxe-regex -S "$search_string" --pretty=format:"%C(yellow)%h%Creset -%C(auto)%d%Creset %s %C(green)(%cr) %C(bold blue)<%an>%Creset" | fzf --ansi --no-sort --preview="git show --color=always {1}" --preview-window=right:70%:wrap | awk '{print $1}'
}

function gc() {
  git commit -v -a -m "$*"
}

function gd() {
  git difftool $1 -t Kaleidoscope -y
}

function gbt() {
  git checkout -b $1 --track origin/$1
}

git-add-origin() {
  local remote_name="${1:-origin}"
  local repo_name=$(gh repo view --json name --jq '.name')
  git remote add "$remote_name" "https://github.com/iloveitaly/$repo_name.git"
}

function git-squash-custom-branch {
  # Check if the .git-custom-branch file exists
  if [[ ! -f ".git-custom-branch" ]]; then
    echo "Error: .git-custom-branch file does not exist"
    exit 1
  fi

  # Check for unstaged changes
  if [[ -n "$(git diff --name-only)" ]]; then
    echo "Error: You have unstaged changes. Please commit or stash them."
    exit 1
  fi

  # determine if master is main, or actually master
  local master_branch=$(git branch -l master main | sed 's/^* //' | xargs)

  # Checkout to the master branch
  git checkout $master_branch

  # Pull the latest changes from the master branch
  git pull origin $master_branch

  # Check if the 'custom' branch already exists and delete it if it does
  if git show-ref --verify --quiet refs/heads/custom; then
    git branch -D custom
  fi

  # Read the branch names from the .git-custom-branch file
  branches=($(< .git-custom-branch))

  # is there more than one entry?
  if [[ ${#branches[@]} -lt 2 ]]; then
    echo "Error: .git-custom-branch file must contain at least two branches"
    exit 1
  fi

  # Checkout to a new branch named 'custom' from the latest master
  git checkout -b custom

  git merge "${branches[@]}" --no-ff --message "Merged and squashed ${branches[@]}"
}

# TODO should probably remove
# https://blog.takanabe.tokyo/en/2020/04/remove-squash-merged-local-git-branches/
function git-clean-squash-and-merge() (
  set -euo pipefail

  # xargs to trim whitespace https://stackoverflow.com/questions/369758/how-to-trim-whitespace-from-a-bash-variable
  local master_branch=$(git branch -l master main | sed 's/^* //' | xargs)
  echo "Using $master_branch as master"

  git checkout -q $master_branch
  git for-each-ref refs/heads/ "--format=%(refname:short)" | while read branch; do
    local ancestor=$(git merge-base $master_branch $branch)

    if [[ $(git cherry main $(git commit-tree $(git rev-parse $branch'^{tree}') -p $ancestor -m _)) == "-"* ]]; then
      git branch -D $branch
    fi
  done
)

# convert a pdf to a jpeg for usage in gpt-v
# ChatGPT cannot handle 3p documents
# TODO try to group content into two-page pairs in the future: https://stackoverflow.com/questions/17025515/converting-a-multi-page-pdf-to-multiple-pages-using-a-single-command
convert-pdf-to-jpeg() {
  local filepath=$1
  local outputpath="${filepath:r}"

  # the position of `filepath` matters! Put this before the operators
  magick -density 300 "${filepath}" -alpha remove -resize 1024x -quality 100 "${outputpath%.*}-%d.jpeg"

  # select the first output
  open -R "$outputpath-0.jpeg"
}

render-git-template() {
  local GH_USERNAME=$(gh repo view --json owner --jq '.owner.login' | tr -d '[:space:]')
  local GH_REPO=$(gh repo view --json name --jq '.name' | tr -d '[:space:]')
  local TEMPLATE=$(pbpaste)

  TEMPLATE=${TEMPLATE//USERNAME/$GH_USERNAME}
  TEMPLATE=${TEMPLATE//REPO/$GH_REPO}
  echo $TEMPLATE | tr -ds '\n' ' '
}

# make a gif out of the last recorded video
function makegif() {
  # make sure to include trailing slash
  # TODO we should be able to determine the default SS directly automatically
  screenshot_dir=~/Desktop/

  latest_movie=$screenshot_dir`/bin/ls -tp "$screenshot_dir" | grep '.*\.mov' | head -n 1`
  gif_destination=`echo "$latest_movie" | sed 's/.mov/.gif/'`

  # `brew install ffmpeg gifsicle`
  ffmpeg -i "$latest_movie" -r 10 -f gif - | gifsicle > "$gif_destination"

  echo $gif_destination
  open -a "Google Chrome" "$gif_destination"
}

function httpless {
  http --pretty=all --print=hb "$@" | less -R
}

# Explore a JSON file using Node.
#
# Usage:
#
#     nq <node expression> <file>
#     nq <file>
#
# Examples:
#
#     # Evaluate a JavaScript expression with `$` substituted for the parsed
#     # `data.json`
#     nq '$.filter(d => !!d).map(d => d.length)' data.json
#
#     # Launch an interactive node REPL with the `$` variable assigned to the
#     # parsed `data.json`
#     nq 'data.json'
#
nq() {
  if [ $# -gt 1 ]; then
    node -e "const $ = JSON.parse(require('fs').readFileSync('$2')); console.log($1)"
  else
    node -i -e "const $ = JSON.parse(require('fs').readFileSync('$1'))"
  fi
}

# ripgrep "only": only display the matching text in the first capture group
# this is helpful for selecting and transforming
rgo() {
  params=()

  # check if the user is passing in `-r`, if not, then default to a basic option
  if ((${@[(I)*-r*]} == 0)); then
    params+=("-r \$1")
  fi

  rg $@ $params --no-filename --no-column --no-line-number --color never --only-matching
}

# TODO extract to `.widgets`
# https://github.com/fearphage/dotfiles-1/blob/9fe03f0fe891ab5e38423fb4b9e185526407fb02/.zsh/config/widgets.zsh#L16
# function custom-fzf-execute-widget() {
#     if (! hash fzf &>/dev/null) {
#         return 1
#     }

#     local selected=$(
#         zle -al \
#             # | command grep --extended-regexp --invert-match '(^orig|^\.|^_)' \
#             | fzf \
#                 --tac \
#                 --nth='2..,..' \
#                 --tiebreak='index' \
#                 --prompt=':'
#     )

#     local stat=$?

#     if [[ "$selected" != '' ]] {
#         echo $selected
#         zle $selected
#     }

#     return $stat
# }

# password protected pdfs are such a pain, this removes the password protection
decryptpdf() {
  echo "Enter password followed by <enter> followed by <ctrl-D>"
  qpdf --decrypt --password-file=- --replace-input "${1}"
}

# even with a massive drive, these LLM models + git history can take up a lot of space
inspect-space() {
  (cd / && sudo ncdu --exclude /System/ --exclude /Applications --exclude "/Library/Application Support/ArqAgentAPFS.noindex" --confirm-quit)
}

# find and replace across files in the current directory
function find-replace() {
  if [ $# -lt 2 ]; then
    echo "Usage: find-replace <find_string> <replace_string>"
    return 1
  fi

  local find_string=$1
  local replace_string=$2
  local files=( $(rg -uu --glob '!.git/**' --glob '!.venv' --glob '!.pnpm' --glob '!node_modules' --glob '!.tox' --glob '!cdk.out' -l --fixed-strings "$find_string") )

  echo "${#files[@]} files found."

  for file in "${files[@]}"; do
    # sd is modern replacement for sed
    sd --preview --fixed-strings "$find_string" "$replace_string" "$file"

    read "confirmation?Confirm replace in '$file'. [y/n]:"

    if [[ $confirmation =~ ^[Yy]$ ]]; then
      sd --fixed-strings "$find_string" "$replace_string" "$file"
    fi
  done
}

# SSH tunneling

function find_random_open_port() {
  local start_port=${1:-1024}
  local max_attempts=100
  local attempt=0
  local port=$start_port

  while (( attempt < max_attempts )); do
    if ! nc -z localhost $port 2>/dev/null; then
      echo $port
      return
    fi
    port=$((port + 1))
    attempt=$((attempt + 1))
  done

  echo "No open port found after $max_attempts attempts, starting from $start_port." > /dev/stderr
  return 1
}


function ssh-tunnel() {
  if [ $# -lt 2 ]; then
    echo "Usage: ssh-tunnel remote_host remote_port [local_port]"
    echo "This function sets up SSH port forwarding."
    return 1
  fi

  local remote_host=$1
  local remote_port=$2
  local local_port=${3:-$(find-random-open-port $remote_port)}

  if [[ -z $local_port ]]; then
    echo "Failed to find an open local port."
    return 1
  fi

  echo "Forwarding local port $local_port to remote port $remote_port on $remote_host..."
  set -x
  ssh $remote_host -L ${local_port}:localhost:${remote_port}
}

# an entire website to a folder
# https://superuser.com/questions/55040/save-a-single-web-page-with-background-images-with-wget/136335#136335
scrape-website() {
  wget -E -H -k -K -p -e robots=off $@
}

###########################
# File opening functions
###########################

# open "yank.tmux:56:109:" at the right line in your terminal
open_in_nano() {
  # Read the input string into variables, splitting by ':'
  IFS=':' read file line column _other <<< "$1"
  # Open the file at the specified line. Nano doesn't support specific column.
  nano +$line "$file" < /dev/tty
}

open_in_vscode() {
  # git-fuzzy will pass a string that looks like `M  bin/run.js` or ` M bin/run.js`

  # write a ripgrep command which:
  # * ` M bin/run.js` => `bin/run.js`
  # * `test/scraper.test.js:25:40` => `test/scraper.test.js:25:40`
  # * `test/scraper.test.js` => `test/scraper.test.js`
  # * `test/scraper.test.js:25:40: something` => `test/scraper.test.js:25
  # assume each of inputs are passed on a single line and are only passed one at a time

  local file=$(pcregrep -o2 "(^\s?M\s)?(.*)" <<< "$1")
  IFS=':' read file line column _other <<< "$file"

  # remove multiple slashes that could have been passed from `file:///` references
  file=$(echo "$file" | sed 's|^/{2,}|/|')

  code --goto "$file:$line:$column"
}

open_in_cat() {
  # TODO jump to specific line number via less
  # wrapping doesn't work the way you would think:
  # bat Makefile --highlight-line 136 --paging=never --wrap=character --terminal-width=150
  # TODO https://github.com/sharkdp/bat/issues/2527

  IFS=':' read file line column _other <<< "$1"

  # output command executed via local shopt
  # setopt local_options xtrace

  bat $file --highlight-line "$line"
}

source ~/.node-functions